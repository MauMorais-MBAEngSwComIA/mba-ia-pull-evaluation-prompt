# Prompt Evaluation: Bug to User Story

Pipeline completo de **Engenharia de Prompt** para converter Bug Reports em User Stories no padr√£o INVEST, com avalia√ß√£o automatizada via **LangChain** e **LangSmith**.

## üéØ Objetivo

Transformar relatos de bugs t√©cnicos (muitas vezes curtos ou confusos) em User Stories estruturadas, com crit√©rios de aceite claros e contexto t√©cnico preservado. O projeto demonstra como t√©cnicas avan√ßadas de Prompt Engineering melhoram a qualidade de sa√≠da de LLMs de forma mensur√°vel.

## üõ†Ô∏è Stack Tecnol√≥gico

| Componente      | Tecnologia                 |
| --------------- | -------------------------- |
| Linguagem       | Python 3.9+                |
| Orquestra√ß√£o  | LangChain                  |
| Observabilidade | LangSmith                  |
| LLM (Gerador)   | Google Gemini 2.0 Flash    |
| LLM (Avaliador) | Google Gemini 2.5 Flash    |
| M√©tricas       | LLM-as-a-Judge customizado |
| Testes          | Pytest                     |

---

## üî¨ T√©cnicas Aplicadas (Fase 2)

O prompt V2 combina **4 t√©cnicas avan√ßadas** de Prompt Engineering:

### 1. Role Prompting (Persona)

Define uma persona especializada de **Product Owner S√™nior** com 15 anos de experi√™ncia em metodologias √°geis.

```
Voce e um Product Owner Senior com 15 anos de experiencia em metodologias ageis.
Sua especialidade e transformar Bug Reports em User Stories profissionais e completas.
```

> **Impacto:** Direciona o LLM a adotar vocabul√°rio t√©cnico adequado e priorizar valor de neg√≥cio. Tone atingiu **0.97** com `gemini-2.0-flash`.

### 2. Chain of Thought (CoT) ‚Äî Via Se√ß√µes Estruturadas

Em vez de racioc√≠nio interno escondido em tags XML, o CoT √© externalizado na sa√≠da via se√ß√£o **Contexto T√©cnico**, que obriga o modelo a analisar e preservar todos os dados t√©cnicos do bug.

```
## Contexto Tecnico
- **Problema identificado**: [descri√ß√£o t√©cnica extra√≠da do bug]
- **Componentes afetados**: [lista de componentes]
- **Metricas/Limites**: [dados num√©ricos]
```

> **Impacto:** Completeness subiu de 0.88 (V1) para **0.97** (V2) ‚Äî o modelo preserva todos os dados t√©cnicos do bug original.

### 3. Few-Shot Learning

Um exemplo completo inline (Bug Report ‚Üí User Story com 3 cen√°rios Gherkin + Contexto T√©cnico) serve como "molde" para o formato e n√≠vel de detalhe esperado.

> **Impacto:** Acceptance Criteria subiu de 0.88 (V1) para **0.97** (V2). O exemplo rico em Gherkin ensina o modelo a produzir cen√°rios espec√≠ficos e test√°veis.

### 4. Output Structuring (Formato Obrigat√≥rio)

8 regras cr√≠ticas expl√≠citas + template r√≠gido que for√ßa a estrutura exata da User Story:

- **Anti-preamble**: Pro√≠be sauda√ß√µes como "Claro!", for√ßando resposta direta
- **Persona espec√≠fica**: Pro√≠be "Como um usu√°rio" gen√©rico
- **Quantidade m√≠nima**: 3-7 cen√°rios Gherkin obrigat√≥rios
- **Benef√≠cio real**: "Para que" deve expressar valor mensur√°vel

> **Impacto:** User Story Format atingiu **0.99** ‚Äî a melhor m√©trica do V2.

---

## üìä Resultados Finais

Avalia√ß√£o com **34 exemplos** (15 originais + 19 curados). Gerador: `gemini-2.0-flash`. Avaliador: `gemini-2.5-flash` (LLM-as-Judge independente).

| M√©trica                          | V1 (Baseline) |  V2 (Otimizado)  | Meta (‚â• 0.9) |   Œî Melhoria   |
| --------------------------------- | :-----------: | :--------------: | :-----------: | :--------------: |
| **Tone**                    |    0.9476    | **0.9741** |   ‚úÖ ambos   | **+0.027** |
| **Acceptance Criteria**     |   0.8838 ‚ùå   | **0.9688** |   ‚úÖ s√≥ V2   | **+0.085** |
| **User Story Format**       |    0.9529    | **0.9894** |   ‚úÖ ambos   | **+0.037** |
| **Completeness**            |    0.9288    | **0.9721** |   ‚úÖ ambos   | **+0.043** |
| **F1 Score** *(auxiliar)* |    0.8325    |      0.8489      |      ‚Äî      |      +0.016      |

> **Destaque:** O V1 falha no threshold de Acceptance Criteria (0.88 < 0.9). O V2 resolve esta defici√™ncia (+8.5%) e melhora **todas** as demais m√©tricas simultaneamente. O F1 Score √© uma m√©trica auxiliar (sobreposi√ß√£o de tokens) ‚Äî valores abaixo de 0.9 s√£o esperados.

### üìê Configura√ß√£o de Avalia√ß√£o

| Aspecto                    | Detalhe                                                                                              |
| -------------------------- | ---------------------------------------------------------------------------------------------------- |
| **Modelo Gerador**   | `gemini-2.0-flash` (mesmo para V1 e V2)                                                            |
| **Modelo Avaliador** | `gemini-2.5-flash` (LLM-as-Judge independente)                                                     |
| **Justificativa**    | O avaliador precisa ser mais capaz que o gerador para distinguir qualidade entre "bom" e "excelente" |

### üîó Experimentos no LangSmith

- **Dataset (34 exemplos)**: [Ver no LangSmith](https://smith.langchain.com/o/4edf22f3-ecb6-499b-b514-311998f18731/datasets/6e40fce8-8415-4916-bf24-1aaf2b640f21?tab=1)
- **Experimento V1**: [Ver resultados no LangSmith](https://smith.langchain.com/o/4edf22f3-ecb6-499b-b514-311998f18731/datasets/6e40fce8-8415-4916-bf24-1aaf2b640f21/compare?selectedSessions=6ad15198-3eb4-44ac-b1ca-9d7e8762e764)
- **Experimento V2**: [Ver resultados no LangSmith](https://smith.langchain.com/o/4edf22f3-ecb6-499b-b514-311998f18731/datasets/6e40fce8-8415-4916-bf24-1aaf2b640f21/compare?selectedSessions=f18833fe-490e-4021-9f9e-582a1aab8cdb)
- **Compara√ß√£o V1 x V2**: [Ver resultados no LangSmith](https://smith.langchain.com/o/4edf22f3-ecb6-499b-b514-311998f18731/datasets/6e40fce8-8415-4916-bf24-1aaf2b640f21/compare?selectedSessions=f18833fe-490e-4021-9f9e-582a1aab8cdb%2C6ad15198-3eb4-44ac-b1ca-9d7e8762e764&source=f18833fe-490e-4021-9f9e-582a1aab8cdb)

### üì∏ Screenshots

![Resultado do Experimento V2 no LangSmith](docs/screenshots/experiment_v2.png)

![Compara√ß√£o V1 vs V2 no LangSmith](docs/screenshots/comparison_v1_v2.png)

---

## üöÄ Como Executar

### Pr√©-requisitos

```bash
pip install -r requirements.txt
```

Crie o arquivo `.env` a partir do template:

```bash
cp .env.example .env
# Preencha: LANGSMITH_API_KEY, GOOGLE_API_KEY, LANGCHAIN_PROJECT
```

### Sincronizar Dataset com LangSmith

```bash
python src/upload_dataset.py
```

### Rodar Avalia√ß√£o Completa (V1 e V2)

```bash
# Avaliar prompt V1 (baseline) ‚Äî gerador 2.0, avaliador 2.5
python src/evaluate.py --prompt bug_to_user_story_v1 --model gemini-2.0-flash --evaluator-model gemini-2.5-flash

# Avaliar prompt V2 (otimizado) ‚Äî gerador 2.0, avaliador 2.5
python src/evaluate.py --prompt bug_to_user_story_v2 --model gemini-2.0-flash --evaluator-model gemini-2.5-flash
```

### Exemplo Pr√°tico de Uso

**Entrada (Bug Report):**

```
O bot√£o 'Salvar' na tela de perfil n√£o funciona quando o nome
cont√©m caracteres especiais (√ß, √£, √©). Retorna erro 500.
```

**Sa√≠da gerada pelo V2:**

```markdown
# Salvar Perfil de Usuario com Caracteres Especiais

**Como** um usuario cadastrado na plataforma,
**Eu quero** salvar meu perfil com qualquer caractere no nome sem encontrar erros,
**Para que** eu possa usar meu nome real e manter meus dados atualizados sem frustracoes.

## Criterios de Aceite

### Cenario 1: Salvamento bem-sucedido com caracteres especiais
- **Dado** que estou na tela de edicao de perfil
- **Quando** insiro um nome com caracteres especiais e clico em Salvar
- **Entao** o perfil deve ser salvo com sucesso retornando HTTP 200
- **E** o nome deve ser exibido corretamente em todas as paginas

### Cenario 2: Prevencao do Erro 500 atual
- **Dado** que o sistema recebe um nome com caracteres nao-ASCII
- **Quando** tenta persistir os dados
- **Entao** nao deve ocorrer Erro 500

### Cenario 3: Validacao no frontend antes do envio
- **Dado** que estou preenchendo o campo de nome
- **Quando** insiro caracteres validos de qualquer idioma
- **Entao** o frontend deve aceitar a entrada sem bloqueio

## Contexto Tecnico
- **Problema identificado**: Erro 500 ao salvar perfil com caracteres especiais
- **Componentes afetados**: Tela de perfil, API de salvamento, banco de dados
- **Severidade**: Alta
```

### Testes de Valida√ß√£o do Prompt

```bash
pytest tests/test_prompts.py -v
```

**Resultado esperado:** 30 testes passando, validando:

- Exist√™ncia de System Prompt
- Defini√ß√£o de Persona (Role)
- Exig√™ncia de formato Markdown/User Story
- Presen√ßa de Few-Shot examples
- Aus√™ncia de marcadores `[TODO]`
- Uso de pelo menos 2 t√©cnicas (via metadados YAML)

### Push do Prompt para o LangSmith Hub

```bash
python src/push_prompts.py
```

---

## üìÇ Estrutura do Projeto

```
prompt-evaluation-langchain-langsmith/
‚îú‚îÄ‚îÄ prompts/
‚îÇ   ‚îú‚îÄ‚îÄ bug_to_user_story_v1.yml      # Prompt Original (Baseline)
‚îÇ   ‚îî‚îÄ‚îÄ bug_to_user_story_v2.yml      # Prompt Otimizado (4 t√©cnicas)
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ evaluate.py                   # Motor de avalia√ß√£o (LLM-as-Judge)
‚îÇ   ‚îú‚îÄ‚îÄ upload_dataset.py             # Sincroniza√ß√£o do dataset com LangSmith
‚îÇ   ‚îú‚îÄ‚îÄ push_prompts.py               # Publica√ß√£o no LangSmith Hub
‚îÇ   ‚îú‚îÄ‚îÄ pull_prompts.py               # Captura do LangSmith Hub
‚îÇ   ‚îú‚îÄ‚îÄ metrics.py                    # M√©tricas customizadas (Tone, AC, Format, Completeness)
‚îÇ   ‚îî‚îÄ‚îÄ utils.py                      # Utilit√°rios e configura√ß√£o de LLM
‚îú‚îÄ‚îÄ datasets/
‚îÇ   ‚îî‚îÄ‚îÄ bug_to_user_story.jsonl       # Dataset de avalia√ß√£o (34 exemplos)
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îî‚îÄ‚îÄ test_prompts.py               # 30 testes automatizados de valida√ß√£o
‚îú‚îÄ‚îÄ docs/                             # Documenta√ß√£o e crit√©rios do desafio
‚îú‚îÄ‚îÄ .env.example                      # Template de configura√ß√£o
‚îú‚îÄ‚îÄ requirements.txt                  # Depend√™ncias Python
‚îî‚îÄ‚îÄ README.md                         # Este arquivo
```

---

## üìã Itera√ß√µes do Prompt (Hist√≥rico)

| Vers√£o      | Modelo    | T√©cnicas                                  |     Comp.     |       AC       |     Format     |      Tone      |
| ------------ | --------- | ------------------------------------------ | :------------: | :------------: | :------------: | :------------: |
| **V1** | 2.0-flash | Zero-shot                                  |      0.93      |    0.88 ‚ùå    |      0.95      |      0.95      |
| **V2** | 2.0-flash | Role + CoT + Few-Shot + Output Structuring | **0.97** | **0.97** | **0.99** | **0.97** |

> O V2 foi desenvolvido em 4 itera√ß√µes: (1) XML Isolation + CoT interno (V2 original), (2) remo√ß√£o do XML + CoT na sa√≠da + 2 Few-Shot ricos (V3), (3) an√°lise profunda dos avaliadores + anti-preamble + persona espec√≠fica + regras de quantidade (V4), (4) promo√ß√£o da V4 para V2 final.

---

**Desenvolvido como parte do Desafio T√©cnico de Prompt Engineering ‚Äî MBA em Engenharia de Software com IA.**
